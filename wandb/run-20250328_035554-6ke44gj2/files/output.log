Loading data statistics...
/root/miniconda3/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.
  warnings.warn(
Loaded pre-trained MARC TUL classifier
Data shape for lat_lon: (2052, 144, 2)
Data shape for day: (2052, 144, 7)
Data shape for hour: (2052, 144, 24)
Data shape for category: (2052, 144, 10)
Mismatch for category: expected 2052, got 10
Rebuilding model with correct input shapes...
Model rebuilt successfully!
Starting training for 2000 epochs with early stopping (patience=20)...
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m4s[0m 48ms/step
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m2s[0m 32ms/step
Input shapes - Day: (256, 144), Hour: (256, 144), Category: (256, 144), Lat_lon: (256, 144, 40)
Day range: [0, 6]
TUL predictions shape: (256, 193)
Rewards shape: (256, 1), min: -4.6590094566345215, max: 1.4864425659179688, mean: -3.141351044178009e-06
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m2s[0m 32ms/step
Advantage stats - min: 0.0002, max: 1.0000, mean: 0.7582, std: 0.1627
Saved best model as best_early_stopping_model

New best model saved at epoch 0 with reward -0.0000
Saved best model as best_reward_model
New best reward: -0.0000 at epoch 0
Saved best model as best_g_loss_model
New best generator loss: 758.1620 at epoch 0
Saved best model as best_d_loss_model
New best discriminator loss: 1.7165 at epoch 0
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m4s[0m 4s/step
Epoch 0/2000
D_real: 0.6884, D_fake: 2.7447, G: 758.1620, C: 4.3042
Reward: -0.0000
Model weights saved for epoch 0
Model architectures saved for epoch 0
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 34ms/step
Input shapes - Day: (256, 144), Hour: (256, 144), Category: (256, 144), Lat_lon: (256, 144, 40)
Day range: [0, 6]
TUL predictions shape: (256, 193)
Rewards shape: (256, 1), min: -5.0, max: 1.6236085891723633, mean: 0.006061406806111336
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step
Advantage stats - min: 0.0001, max: 1.0000, mean: 0.7558, std: 0.1456
Saved best model as best_early_stopping_model

New best model saved at epoch 1 with reward 0.0061
Saved best model as best_reward_model
New best reward: 0.0061 at epoch 1
Saved best model as best_g_loss_model
New best generator loss: 756.9941 at epoch 1
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 41ms/step
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 30ms/step
Input shapes - Day: (256, 144), Hour: (256, 144), Category: (256, 144), Lat_lon: (256, 144, 40)
Day range: [0, 6]
TUL predictions shape: (256, 193)
Rewards shape: (256, 1), min: -2.540480613708496, max: 3.1894001960754395, mean: -1.1362135410308838e-06
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 30ms/step
Advantage stats - min: 0.0002, max: 1.0000, mean: 0.4435, std: 0.1745
Saved best model as best_g_loss_model
New best generator loss: 652.4864 at epoch 2
Saved best model as best_d_loss_model
New best discriminator loss: 1.3037 at epoch 2
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
Input shapes - Day: (256, 144), Hour: (256, 144), Category: (256, 144), Lat_lon: (256, 144, 40)
Day range: [0, 6]
TUL predictions shape: (256, 193)
Rewards shape: (256, 1), min: -1.8993748426437378, max: 3.9161620140075684, mean: 1.3969838619232178e-08
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 32ms/step
Advantage stats - min: 0.0002, max: 1.0000, mean: 0.3267, std: 0.1719
Saved best model as best_g_loss_model
New best generator loss: 571.0446 at epoch 3
Saved best model as best_d_loss_model
New best discriminator loss: 0.9726 at epoch 3
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 31ms/step
Input shapes - Day: (256, 144), Hour: (256, 144), Category: (256, 144), Lat_lon: (256, 144, 40)
Day range: [0, 6]
TUL predictions shape: (256, 193)
Rewards shape: (256, 1), min: -1.7495664358139038, max: 4.707172393798828, mean: 4.917383193969727e-07
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step
Advantage stats - min: 0.0002, max: 1.0000, mean: 0.2711, std: 0.1549
Saved best model as best_g_loss_model
New best generator loss: 511.0518 at epoch 4
Saved best model as best_d_loss_model
New best discriminator loss: 0.7687 at epoch 4
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step
Input shapes - Day: (256, 144), Hour: (256, 144), Category: (256, 144), Lat_lon: (256, 144, 40)
Day range: [0, 6]
TUL predictions shape: (256, 193)
Rewards shape: (256, 1), min: -1.5341150760650635, max: 5.0, mean: -0.0009678341448307037
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 32ms/step
Advantage stats - min: 0.0002, max: 1.0000, mean: 0.2348, std: 0.1523
Saved best model as best_g_loss_model
New best generator loss: 465.0022 at epoch 5
Saved best model as best_d_loss_model
New best discriminator loss: 0.6359 at epoch 5
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 31ms/step
Input shapes - Day: (256, 144), Hour: (256, 144), Category: (256, 144), Lat_lon: (256, 144, 40)
Day range: [0, 6]
TUL predictions shape: (256, 193)
Rewards shape: (256, 1), min: -1.505941390991211, max: 5.0, mean: -0.0048823244869709015
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 32ms/step
Advantage stats - min: 0.0001, max: 1.0000, mean: 0.2308, std: 0.1494
Saved best model as best_g_loss_model
New best generator loss: 431.5499 at epoch 6
Saved best model as best_d_loss_model
New best discriminator loss: 0.5423 at epoch 6
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 32ms/step
Input shapes - Day: (256, 144), Hour: (256, 144), Category: (256, 144), Lat_lon: (256, 144, 40)
Day range: [0, 6]
TUL predictions shape: (256, 193)
Rewards shape: (256, 1), min: -1.3811205625534058, max: 4.00860595703125, mean: 1.6260892152786255e-06
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 31ms/step
Advantage stats - min: 0.0002, max: 1.0000, mean: 0.2564, std: 0.1855
Saved best model as best_g_loss_model
New best generator loss: 409.6548 at epoch 7
Saved best model as best_d_loss_model
New best discriminator loss: 0.4724 at epoch 7
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 30ms/step
Input shapes - Day: (256, 144), Hour: (256, 144), Category: (256, 144), Lat_lon: (256, 144, 40)
Day range: [0, 6]
TUL predictions shape: (256, 193)
Rewards shape: (256, 1), min: -1.1897538900375366, max: 5.0, mean: -0.005405243486166
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 30ms/step
Advantage stats - min: 0.0002, max: 1.0000, mean: 0.1915, std: 0.1568
Saved best model as best_g_loss_model
New best generator loss: 385.4117 at epoch 8
Saved best model as best_d_loss_model
New best discriminator loss: 0.4184 at epoch 8
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 47ms/step
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 32ms/step
Input shapes - Day: (256, 144), Hour: (256, 144), Category: (256, 144), Lat_lon: (256, 144, 40)
Day range: [0, 6]
TUL predictions shape: (256, 193)
Rewards shape: (256, 1), min: -1.470878005027771, max: 3.766403913497925, mean: -2.5704503059387207e-07
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 30ms/step
Advantage stats - min: 0.0002, max: 1.0000, mean: 0.2810, std: 0.1909
Saved best model as best_g_loss_model
New best generator loss: 374.9690 at epoch 9
Saved best model as best_d_loss_model
New best discriminator loss: 0.3755 at epoch 9
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 32ms/step
Input shapes - Day: (256, 144), Hour: (256, 144), Category: (256, 144), Lat_lon: (256, 144, 40)
Day range: [0, 6]
TUL predictions shape: (256, 193)
Rewards shape: (256, 1), min: -1.360750436782837, max: 5.0, mean: -0.0013971030712127686
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 31ms/step
Advantage stats - min: 0.0002, max: 1.0000, mean: 0.2138, std: 0.1560
Saved best model as best_g_loss_model
New best generator loss: 360.3202 at epoch 10
Saved best model as best_d_loss_model
New best discriminator loss: 0.3406 at epoch 10
Epoch 10/2000
D_real: 0.3485, D_fake: 0.3327, G: 360.3202, C: 5.9374
Reward: -0.0014
Model weights saved for epoch 10
Model architectures saved for epoch 10
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step
Input shapes - Day: (256, 144), Hour: (256, 144), Category: (256, 144), Lat_lon: (256, 144, 40)
Day range: [0, 6]
TUL predictions shape: (256, 193)
Rewards shape: (256, 1), min: -1.328212857246399, max: 3.5239837169647217, mean: -1.4882534742355347e-06
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 31ms/step
Advantage stats - min: 0.0002, max: 1.0000, mean: 0.2739, std: 0.2060
Saved best model as best_g_loss_model
New best generator loss: 353.1172 at epoch 11
Saved best model as best_d_loss_model
New best discriminator loss: 0.3116 at epoch 11
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 31ms/step
Input shapes - Day: (256, 144), Hour: (256, 144), Category: (256, 144), Lat_lon: (256, 144, 40)
Day range: [0, 6]
TUL predictions shape: (256, 193)
Rewards shape: (256, 1), min: -1.1686382293701172, max: 5.0, mean: -0.008938275277614594
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 29ms/step
Advantage stats - min: 0.0002, max: 1.0000, mean: 0.1881, std: 0.1535
Saved best model as best_g_loss_model
New best generator loss: 340.4254 at epoch 12
Saved best model as best_d_loss_model
New best discriminator loss: 0.2872 at epoch 12
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 29ms/step
Input shapes - Day: (256, 144), Hour: (256, 144), Category: (256, 144), Lat_lon: (256, 144, 40)
Day range: [0, 6]
TUL predictions shape: (256, 193)
Rewards shape: (256, 1), min: -1.25990891456604, max: 5.0, mean: -0.0011581657454371452
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 32ms/step
Advantage stats - min: 0.0002, max: 1.0000, mean: 0.2012, std: 0.1588
Saved best model as best_g_loss_model
New best generator loss: 330.4813 at epoch 13
Saved best model as best_d_loss_model
New best discriminator loss: 0.2663 at epoch 13
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 44ms/step
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 31ms/step
Input shapes - Day: (256, 144), Hour: (256, 144), Category: (256, 144), Lat_lon: (256, 144, 40)
Day range: [0, 6]
TUL predictions shape: (256, 193)
Rewards shape: (256, 1), min: -1.058603286743164, max: 5.0, mean: -0.01400437019765377
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 30ms/step
Advantage stats - min: 0.0001, max: 1.0000, mean: 0.1725, std: 0.1485
Saved best model as best_g_loss_model
New best generator loss: 319.9518 at epoch 14
Saved best model as best_d_loss_model
New best discriminator loss: 0.2482 at epoch 14
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 30ms/step
Input shapes - Day: (256, 144), Hour: (256, 144), Category: (256, 144), Lat_lon: (256, 144, 40)
Day range: [0, 6]
TUL predictions shape: (256, 193)
Rewards shape: (256, 1), min: -1.2951977252960205, max: 5.0, mean: -0.009702010080218315
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 29ms/step
Advantage stats - min: 0.0001, max: 1.0000, mean: 0.2043, std: 0.1489
Saved best model as best_g_loss_model
New best generator loss: 312.7249 at epoch 15
Saved best model as best_d_loss_model
New best discriminator loss: 0.2325 at epoch 15
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 31ms/step
Input shapes - Day: (256, 144), Hour: (256, 144), Category: (256, 144), Lat_lon: (256, 144, 40)
Day range: [0, 6]
TUL predictions shape: (256, 193)
Rewards shape: (256, 1), min: -1.1153831481933594, max: 5.0, mean: -0.020354680716991425
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 28ms/step
Advantage stats - min: 0.0001, max: 1.0000, mean: 0.1792, std: 0.1358
Saved best model as best_g_loss_model
New best generator loss: 304.8689 at epoch 16
Saved best model as best_d_loss_model
New best discriminator loss: 0.2186 at epoch 16
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 40ms/step
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 31ms/step
Input shapes - Day: (256, 144), Hour: (256, 144), Category: (256, 144), Lat_lon: (256, 144, 40)
Day range: [0, 6]
TUL predictions shape: (256, 193)
Rewards shape: (256, 1), min: -1.6098231077194214, max: 5.0, mean: -0.017109662294387817
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 31ms/step
Advantage stats - min: 0.0001, max: 1.0000, mean: 0.2411, std: 0.1322
Saved best model as best_g_loss_model
New best generator loss: 301.3240 at epoch 17
Saved best model as best_d_loss_model
New best discriminator loss: 0.2063 at epoch 17
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 42ms/step
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 31ms/step
Input shapes - Day: (256, 144), Hour: (256, 144), Category: (256, 144), Lat_lon: (256, 144, 40)
Day range: [0, 6]
TUL predictions shape: (256, 193)
Rewards shape: (256, 1), min: -1.3449093103408813, max: 5.0, mean: -0.003705233335494995
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 33ms/step
Advantage stats - min: 0.0002, max: 1.0000, mean: 0.2115, std: 0.1544
Saved best model as best_g_loss_model
New best generator loss: 296.5967 at epoch 18
Saved best model as best_d_loss_model
New best discriminator loss: 0.1953 at epoch 18
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 37ms/step
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 30ms/step
Input shapes - Day: (256, 144), Hour: (256, 144), Category: (256, 144), Lat_lon: (256, 144, 40)
Day range: [0, 6]
TUL predictions shape: (256, 193)
Rewards shape: (256, 1), min: -1.4790689945220947, max: 5.0, mean: -0.007663004100322723
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 30ms/step
Advantage stats - min: 0.0001, max: 1.0000, mean: 0.2272, std: 0.1471
Saved best model as best_g_loss_model
New best generator loss: 293.1276 at epoch 19
Saved best model as best_d_loss_model
New best discriminator loss: 0.1854 at epoch 19
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 31ms/step
Input shapes - Day: (256, 144), Hour: (256, 144), Category: (256, 144), Lat_lon: (256, 144, 40)
Day range: [0, 6]
TUL predictions shape: (256, 193)
Rewards shape: (256, 1), min: -1.2364922761917114, max: 5.0, mean: -0.01432737149298191
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 28ms/step
Advantage stats - min: 0.0001, max: 1.0000, mean: 0.1961, std: 0.1438
Saved best model as best_g_loss_model
New best generator loss: 288.5066 at epoch 20
Saved best model as best_d_loss_model
New best discriminator loss: 0.1765 at epoch 20
Epoch 20/2000
D_real: 0.1786, D_fake: 0.1744, G: 288.5066, C: 3.5433
Reward: -0.0143
Model weights saved for epoch 20
Model architectures saved for epoch 20
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 36ms/step
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 31ms/step
Input shapes - Day: (256, 144), Hour: (256, 144), Category: (256, 144), Lat_lon: (256, 144, 40)
Day range: [0, 6]
TUL predictions shape: (256, 193)
Rewards shape: (256, 1), min: -1.174011468887329, max: 5.0, mean: -0.021802149713039398
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 31ms/step
Advantage stats - min: 0.0001, max: 1.0000, mean: 0.1867, std: 0.1356

Early stopping triggered after 20 epochs without improvement
Best model was at epoch 1 with reward 0.0061
Training stopped at epoch 21 due to early stopping.

Training completed. Best model was at epoch 1 with reward 0.0061
[34m[1mwandb[0m: [33mWARNING[0m Symlinked 7 files into the W&B run directory, call wandb.save again to sync new files.
